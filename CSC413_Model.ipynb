{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDo-GMsdFcBb"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bAZ6KmX4FCsi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.optim as optim\n",
        "import kagglehub  # for dataset\n",
        "import os\n",
        "import string\n",
        "import torch\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "from collections import defaultdict\n",
        "from math import ceil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7R7dY5Y2FW1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7842b083-8ba4-47b0-b0c3-fb846be28849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mido\n",
            "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mido) (24.2)\n",
            "Downloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mido\n",
            "Successfully installed mido-1.3.3\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import mido  # for parsing midi files\n",
        "    from mido import MidiFile, MidiTrack, Message, MetaMessage\n",
        "except ModuleNotFoundError:\n",
        "    !pip install mido\n",
        "    import mido\n",
        "    from mido import MidiFile, MidiTrack, Message, MetaMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hwNbVLFsFYSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e35cf8-5197-4f00-bdf0-877ccab93695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fluid-soundfont-gm libevdev2 libfluidsynth3 libgudev-1.0-0 libinput-bin libinput10\n",
            "  libinstpatch-1.0-2 libmd4c0 libmtdev1 libqt5core5a libqt5dbus5 libqt5gui5 libqt5network5\n",
            "  libqt5svg5 libqt5widgets5 libwacom-bin libwacom-common libwacom9 libxcb-icccm4 libxcb-image0\n",
            "  libxcb-keysyms1 libxcb-render-util0 libxcb-util1 libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1\n",
            "  libxkbcommon-x11-0 qsynth qt5-gtk-platformtheme qttranslations5-l10n timgm6mb-soundfont\n",
            "Suggested packages:\n",
            "  fluid-soundfont-gs qt5-image-formats-plugins qtwayland5 jackd\n",
            "The following NEW packages will be installed:\n",
            "  fluid-soundfont-gm fluidsynth libevdev2 libfluidsynth3 libgudev-1.0-0 libinput-bin libinput10\n",
            "  libinstpatch-1.0-2 libmd4c0 libmtdev1 libqt5core5a libqt5dbus5 libqt5gui5 libqt5network5\n",
            "  libqt5svg5 libqt5widgets5 libwacom-bin libwacom-common libwacom9 libxcb-icccm4 libxcb-image0\n",
            "  libxcb-keysyms1 libxcb-render-util0 libxcb-util1 libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1\n",
            "  libxkbcommon-x11-0 qsynth qt5-gtk-platformtheme qttranslations5-l10n timgm6mb-soundfont\n",
            "0 upgraded, 32 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 148 MB of archives.\n",
            "After this operation, 207 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5core5a amd64 5.15.3+dfsg-2ubuntu0.2 [2,006 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevdev2 amd64 1.12.1+dfsg-1 [39.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmtdev1 amd64 1.1.6-1build4 [14.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-common all 2.2.0-1 [54.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom9 amd64 2.2.0-1 [22.0 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput-bin amd64 1.20.0-1ubuntu0.3 [19.9 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput10 amd64 1.20.0-1ubuntu0.3 [131 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmd4c0 amd64 0.4.8-1 [42.0 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5dbus5 amd64 5.15.3+dfsg-2ubuntu0.2 [222 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5network5 amd64 5.15.3+dfsg-2ubuntu0.2 [731 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5gui5 amd64 5.15.3+dfsg-2ubuntu0.2 [3,722 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5widgets5 amd64 5.15.3+dfsg-2ubuntu0.2 [2,561 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5svg5 amd64 5.15.3-1 [149 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fluid-soundfont-gm all 3.1-5.3 [130 MB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libinstpatch-1.0-2 amd64 1.1.6-1 [240 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/universe amd64 timgm6mb-soundfont all 1.3-5 [5,427 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfluidsynth3 amd64 2.2.5-1 [246 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fluidsynth amd64 2.2.5-1 [27.4 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-bin amd64 2.2.0-1 [13.6 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qsynth amd64 0.9.6-1 [305 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qt5-gtk-platformtheme amd64 5.15.3+dfsg-2ubuntu0.2 [130 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qttranslations5-l10n all 5.15.3-1 [1,983 kB]\n",
            "Fetched 148 MB in 7s (20.1 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package libqt5core5a:amd64.\n",
            "(Reading database ... 123633 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libqt5core5a_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libevdev2:amd64.\n",
            "Preparing to unpack .../01-libevdev2_1.12.1+dfsg-1_amd64.deb ...\n",
            "Unpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Selecting previously unselected package libmtdev1:amd64.\n",
            "Preparing to unpack .../02-libmtdev1_1.1.6-1build4_amd64.deb ...\n",
            "Unpacking libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Selecting previously unselected package libgudev-1.0-0:amd64.\n",
            "Preparing to unpack .../03-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n",
            "Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Selecting previously unselected package libwacom-common.\n",
            "Preparing to unpack .../04-libwacom-common_2.2.0-1_all.deb ...\n",
            "Unpacking libwacom-common (2.2.0-1) ...\n",
            "Selecting previously unselected package libwacom9:amd64.\n",
            "Preparing to unpack .../05-libwacom9_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom9:amd64 (2.2.0-1) ...\n",
            "Selecting previously unselected package libinput-bin.\n",
            "Preparing to unpack .../06-libinput-bin_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libinput10:amd64.\n",
            "Preparing to unpack .../07-libinput10_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libmd4c0:amd64.\n",
            "Preparing to unpack .../08-libmd4c0_0.4.8-1_amd64.deb ...\n",
            "Unpacking libmd4c0:amd64 (0.4.8-1) ...\n",
            "Selecting previously unselected package libqt5dbus5:amd64.\n",
            "Preparing to unpack .../09-libqt5dbus5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5network5:amd64.\n",
            "Preparing to unpack .../10-libqt5network5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../11-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../12-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../13-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../14-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../15-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../16-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../17-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../18-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../19-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libqt5gui5:amd64.\n",
            "Preparing to unpack .../20-libqt5gui5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5widgets5:amd64.\n",
            "Preparing to unpack .../21-libqt5widgets5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5svg5:amd64.\n",
            "Preparing to unpack .../22-libqt5svg5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package fluid-soundfont-gm.\n",
            "Preparing to unpack .../23-fluid-soundfont-gm_3.1-5.3_all.deb ...\n",
            "Unpacking fluid-soundfont-gm (3.1-5.3) ...\n",
            "Selecting previously unselected package libinstpatch-1.0-2:amd64.\n",
            "Preparing to unpack .../24-libinstpatch-1.0-2_1.1.6-1_amd64.deb ...\n",
            "Unpacking libinstpatch-1.0-2:amd64 (1.1.6-1) ...\n",
            "Selecting previously unselected package timgm6mb-soundfont.\n",
            "Preparing to unpack .../25-timgm6mb-soundfont_1.3-5_all.deb ...\n",
            "Unpacking timgm6mb-soundfont (1.3-5) ...\n",
            "Selecting previously unselected package libfluidsynth3:amd64.\n",
            "Preparing to unpack .../26-libfluidsynth3_2.2.5-1_amd64.deb ...\n",
            "Unpacking libfluidsynth3:amd64 (2.2.5-1) ...\n",
            "Selecting previously unselected package fluidsynth.\n",
            "Preparing to unpack .../27-fluidsynth_2.2.5-1_amd64.deb ...\n",
            "Unpacking fluidsynth (2.2.5-1) ...\n",
            "Selecting previously unselected package libwacom-bin.\n",
            "Preparing to unpack .../28-libwacom-bin_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom-bin (2.2.0-1) ...\n",
            "Selecting previously unselected package qsynth.\n",
            "Preparing to unpack .../29-qsynth_0.9.6-1_amd64.deb ...\n",
            "Unpacking qsynth (0.9.6-1) ...\n",
            "Selecting previously unselected package qt5-gtk-platformtheme:amd64.\n",
            "Preparing to unpack .../30-qt5-gtk-platformtheme_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package qttranslations5-l10n.\n",
            "Preparing to unpack .../31-qttranslations5-l10n_5.15.3-1_all.deb ...\n",
            "Unpacking qttranslations5-l10n (5.15.3-1) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up qttranslations5-l10n (5.15.3-1) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Setting up libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libmd4c0:amd64 (0.4.8-1) ...\n",
            "Setting up fluid-soundfont-gm (3.1-5.3) ...\n",
            "update-alternatives: using /usr/share/sounds/sf2/FluidR3_GM.sf2 to provide /usr/share/sounds/sf2/default-GM.sf2 (default-GM.sf2) in auto mode\n",
            "update-alternatives: using /usr/share/sounds/sf2/FluidR3_GM.sf2 to provide /usr/share/sounds/sf3/default-GM.sf3 (default-GM.sf3) in auto mode\n",
            "Setting up timgm6mb-soundfont (1.3-5) ...\n",
            "Setting up libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Setting up libinstpatch-1.0-2:amd64 (1.1.6-1) ...\n",
            "Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Setting up libfluidsynth3:amd64 (2.2.5-1) ...\n",
            "Setting up libwacom-common (2.2.0-1) ...\n",
            "Setting up libwacom9:amd64 (2.2.0-1) ...\n",
            "Setting up libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Setting up fluidsynth (2.2.5-1) ...\n",
            "Created symlink /etc/systemd/user/default.target.wants/fluidsynth.service → /usr/lib/systemd/user/fluidsynth.service.\n",
            "Setting up libwacom-bin (2.2.0-1) ...\n",
            "Setting up libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Setting up libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Setting up qsynth (0.9.6-1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pyfluidsynth\n",
            "  Downloading pyfluidsynth-1.3.4-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyfluidsynth) (1.26.4)\n",
            "Downloading pyfluidsynth-1.3.4-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyfluidsynth\n",
            "Successfully installed pyfluidsynth-1.3.4\n",
            "Collecting midi2audio\n",
            "  Downloading midi2audio-0.1.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading midi2audio-0.1.1-py2.py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: midi2audio\n",
            "Successfully installed midi2audio-0.1.1\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from midi2audio import FluidSynth\n",
        "    from IPython import display\n",
        "except ModuleNotFoundError:\n",
        "    !apt install fluidsynth\n",
        "    !pip install --upgrade pyfluidsynth\n",
        "    !pip install midi2audio\n",
        "    from midi2audio import FluidSynth\n",
        "    from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2Q99xKnFyIj"
      },
      "source": [
        "# Midi Functions\n",
        "\n",
        "code from: https://raw.githubusercontent.com/TianyangZhan/AutoMusicGeneration/refs/heads/master/midi_parser.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7OgR8uqGFYvJ"
      },
      "outputs": [],
      "source": [
        "# GLOBAL PARAMETERS\n",
        "unit_time = 0.02  # unit: second \t# the time unit for each time slice (column in the piano roll)\n",
        "highest_note = 127  # pitch value\n",
        "lowest_note = 0  # pitch value\n",
        "pitch_dimension = highest_note - lowest_note + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zf_8oQ8rF8Vi"
      },
      "outputs": [],
      "source": [
        "def parseMidi(midi_file):\n",
        "\t'''\n",
        "\t\tparse midi file into a piano roll and save temporal values\n",
        "\n",
        "\t\tparams:\t\tmidi_file: a midi files for parsing\n",
        "\n",
        "\t\toutput:\t[pianoroll, tempo, resolution]\n",
        "\t\t\t\t\tpianoroll:\ta matrix of size (timestep x pitch_dimension)\n",
        "\t\t\t\t\ttempo: the tempo value from midi file\n",
        "\t\t\t\t\tresolution: the resolution value from midi file\n",
        "\n",
        "\t'''\n",
        "\n",
        "\tmidi_data = MidiFile(midi_file)\n",
        "\n",
        "\t# get music tempo info\n",
        "\tresolution = midi_data.ticks_per_beat\n",
        "\n",
        "\ttrack_tempos = [event.tempo for track in midi_data.tracks for event in track if str(event.type) == \"set_tempo\"]\n",
        "\t# track_tempos += [0]\n",
        "\ttry:\n",
        "\t\ttempo = int(60000000/max(track_tempos)) # get the max track tempo\n",
        "\texcept:\n",
        "\t\t# print(midi_file)\n",
        "\t\ttempo = 60000000\n",
        "\n",
        "\tticks_per_time = resolution*tempo*unit_time/60.0\n",
        "\n",
        "\t#Get maximum ticks across all tracks\n",
        "\ttotal_ticks =0\n",
        "\tfor track in midi_data.tracks:\n",
        "\t\tsum_ticks = sum([event.time for event in track if str(event.type) in ['note_on','note_off','end_of_track']])\n",
        "\t\ttotal_ticks = max(total_ticks,sum_ticks)\n",
        "\n",
        "\ttime_slices = int(ceil(total_ticks/ticks_per_time))\n",
        "\n",
        "\t# slice file into piano roll matrix\n",
        "\tpiano_roll = np.zeros((pitch_dimension, time_slices), dtype=int)\n",
        "\tnote_states = defaultdict(lambda:-1)\n",
        "\n",
        "\tfor track in midi_data.tracks:\n",
        "\n",
        "\t\ttotal_ticks = 0\n",
        "\n",
        "\t\tfor event in track:\n",
        "\n",
        "\t\t\tif str(event.type) == 'note_on' and event.velocity > 0 and event.note in range(lowest_note,highest_note+1):\n",
        "\t\t\t# note is played\n",
        "\n",
        "\t\t\t\ttotal_ticks += event.time\n",
        "\t\t\t\ttime_slice_idx = int(total_ticks/ticks_per_time)\n",
        "\t\t\t\t# count note as played\n",
        "\t\t\t\tnote_idx = event.note - lowest_note\n",
        "\t\t\t\tpiano_roll[note_idx][time_slice_idx] = 1\n",
        "\t\t\t\tnote_states[note_idx] = time_slice_idx\n",
        "\n",
        "\t\t\telif (str(event.type) == 'note_off' or str(event.type) == 'note_on') and event.note in range(lowest_note,highest_note+1):\n",
        "\t\t\t# note is not played\n",
        "\n",
        "\t\t\t\ttotal_ticks += event.time\n",
        "\t\t\t\ttime_slice_idx = int(total_ticks/ticks_per_time)\n",
        "\n",
        "\t\t\t\tif note_states[note_idx] != -1:\t # note was played\n",
        "\t\t\t\t\tpiano_roll[note_idx][note_states[note_idx] : time_slice_idx] = 1\n",
        "\t\t\t\t\tnote_states[note_idx] = -1\n",
        "\n",
        "\treturn piano_roll.T, tempo, resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1YmxEIt_GAKh"
      },
      "outputs": [],
      "source": [
        "#preprocess data directory\n",
        "def getData(file_paths):\n",
        "\t'''\n",
        "\t\tparse midi files into a piano rolls\n",
        "\n",
        "\t\tparams:\t\tfile_paths: paths to midi files (.midi or .mid)\n",
        "\n",
        "\t\toutput:\t\tpianoroll_lst:\ta list of (N = #files) matrices of size (timestep x pitch_dimension)\n",
        "\n",
        "\t'''\n",
        "\t# print(\"Parsing MIDI files\", file_paths)\n",
        "\n",
        "\tpianoroll_lst = []\n",
        "\n",
        "\tfor path in file_paths:\n",
        "\t\tpr,_,_ = parseMidi(path) # don't need temporal values for training\n",
        "\t\tpianoroll_lst.append(pr)\n",
        "\n",
        "\treturn pianoroll_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8ARjAMlwGDQj"
      },
      "outputs": [],
      "source": [
        "def createTrainData(pianoroll_lst, x_length, y_length, tight_window=False):\n",
        "\t'''\n",
        "\t\tcreate X and Y samples from piano roll matrix with a sliding window\n",
        "\n",
        "\t\tparams:\t\tpianoroll_lst: a list of piano roll matrices\n",
        "\t\t\t\t\tx_length: the length of input sequence. for best performance: x_length > y_length\n",
        "\t\t\t\t\ty_length: the length of output sequence. for best performance: y_length < x_length\n",
        "\t\t\t\t\ttight_window: default: False. the step size for shifting the sliding window.\n",
        "\t\t\t\t\t\t\t\t  tight_window=True: shift sliding window by y_length\n",
        "\t\t\t\t\t\t\t\t  tight_window=False: shift sliding window by x_length\n",
        "\n",
        "\t\toutput:\t\t[x,y]: shuffled data for training\n",
        "\t'''\n",
        "\n",
        "\tx = []\n",
        "\ty = []\n",
        "\n",
        "\tfor piano_roll in pianoroll_lst:\n",
        "\t\tpos = 0\n",
        "\t\twhile pos + x_length + y_length < piano_roll.shape[0]:\n",
        "\t\t\tx.append(piano_roll[pos:pos+x_length])\n",
        "\t\t\ty.append(piano_roll [pos+x_length: pos+x_length+y_length])\n",
        "\t\t\tif tight_window:\n",
        "\t\t\t\tpos += y_length\n",
        "\t\t\telse:\n",
        "\t\t\t\tpos += x_length\n",
        "\n",
        "\treturn shuffle(np.array(x),np.array(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hiTh1xieGFdi"
      },
      "outputs": [],
      "source": [
        "# NN output to pianoroll\n",
        "def outputPianoRoll(output, note_threshold=0.1):\n",
        "\t'''\n",
        "\t\tconvert a list of output to piano roll\n",
        "\n",
        "\t\tparams:\t\toutput: a list of prediction result sequence\n",
        "\t\t\t\t\tnote_threshold: default: 0.1. the threshold for a note to be played\n",
        "\n",
        "\t\toutput:\t\tpianoroll_lst:\ta list of matrices of size (timestep x pitch_dimension)\n",
        "\t'''\n",
        "\tpianoroll_lst = []\n",
        "\tfor sequence in output:\n",
        "\n",
        "\t\tfor timeslice in sequence:\n",
        "\t\t\tresult = np.zeros(timeslice.shape)\n",
        "\t\t\tnote_on = [i for i in range(len(timeslice)) if timeslice[i] > note_threshold]\n",
        "\t\t\tresult[note_on] = 1\n",
        "\t\t\tpianoroll_lst.append(result)\n",
        "\n",
        "\treturn np.array(pianoroll_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ISvx3hCFGHja"
      },
      "outputs": [],
      "source": [
        "# pianoroll to MIDI\n",
        "def outputMidi(output_dir, piano_roll, tempo=120, resolution=480, scale=1, velocity=65):\n",
        "\t'''\n",
        "\t\tconvert the piano roll to midi file\n",
        "\n",
        "\t\tparams:\t\toutput_dir: the directory to store output file\n",
        "\t\t\t\t\tpiano_roll: a list of (N = #files) matrices of size (timestep x pitch_dimension)\n",
        "\t\t\t\t\ttempo: default: 120\t\t\tthe tempo value from midi file\n",
        "\t\t\t\t\tresolution: default: 480\tthe resolution value from midi file\n",
        "\t\t\t\t\tscale: default:1\t\t\tthe number of ticks per time slice.\tfor best performance: = length of sequence in one prediction\n",
        "\t\t\t\t\tvelocity: default:65\t\tthe speed/strength to play a note\n",
        "\t'''\n",
        "\n",
        "\n",
        "\tticks_per_time=(resolution*tempo*unit_time)/60.0\n",
        "\n",
        "\tmid = MidiFile(ticks_per_beat = int(resolution))\n",
        "\n",
        "\ttrack = MidiTrack()\n",
        "\ttrack.append(MetaMessage('set_tempo', tempo = int(60000000/tempo), time=0))\n",
        "\n",
        "\tnote_events = [\"note_off\",\"note_on\"]\n",
        "\tlast_state = np.zeros(pitch_dimension)\n",
        "\tlast_index = 0\n",
        "\n",
        "\tfor current_index, current_state in enumerate(np.concatenate((piano_roll, last_state.reshape(1, -1)), axis=0)): # terminate note at the end\n",
        "\n",
        "\t\tdelta = current_state - last_state\n",
        "\t\tlast_state = current_state\n",
        "\n",
        "\t\tfor i in range(len(delta)):\n",
        "\t\t\tif delta[i] == 1 or delta[i] == -1: # play/stop note\n",
        "\t\t\t\tevent = Message(note_events[delta[i] > 0], time=int(scale*(current_index-last_index)*ticks_per_time), velocity=velocity, note=(lowest_note+i))\n",
        "\t\t\t\ttrack.append(event)\n",
        "\t\t\t\tlast_index = current_index\n",
        "\t\t\telse:\n",
        "\t\t\t\tpass # don't change note state\n",
        "\n",
        "\tend = MetaMessage('end_of_track', time=1)\n",
        "\ttrack.append(end)\n",
        "\n",
        "\tmid.tracks.append(track)\n",
        "\tmid.save(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HwnBPHATGS0C"
      },
      "outputs": [],
      "source": [
        "def play_midi(path: str) -> display.Audio:\n",
        "    \"\"\"\n",
        "    Function from CSC311 lab 6.\n",
        "    Displays a playable wav of the given midi file.\n",
        "    \"\"\"\n",
        "    FluidSynth(\"font.sf2\").midi_to_audio(path, 'tmp.wav')\n",
        "    return display.Audio(\"tmp.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4HM5UFC0Gdwz"
      },
      "outputs": [],
      "source": [
        "def display_piano_roll(piano_roll: np.ndarray, name: str) -> None:\n",
        "    \"\"\"\n",
        "    https://medium.com/analytics-vidhya/convert-midi-file-to-numpy-array-in-python-7d00531890c\n",
        "    :param piano_roll:\n",
        "    \"\"\"\n",
        "    plt.plot(range(piano_roll.shape[0]), np.multiply(piano_roll, range(1, piano_roll.shape[1] + 1)), marker='.', markersize=1, linestyle='')\n",
        "    plt.title(name)\n",
        "    plt.xlabel('time step')\n",
        "    plt.ylabel('note')\n",
        "    plt.ylim(bottom=1)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W5qGyaWGj2o"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zxr5xAnGk_r",
        "outputId": "e978f544-9d33-465a-c155-19c690a63100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/hansespinosa2/nin-video-game-midis?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.24M/9.24M [00:00<00:00, 71.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"hansespinosa2/nin-video-game-midis\", force_download=True)\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Bg3BFA4TGmvb"
      },
      "outputs": [],
      "source": [
        "# I found some unreadable files / no name / no tempo\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Nintendo/Wii/MarioKartWii/MushroomGorgeFourHands.mid\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Nintendo/Wii/SuperPaperMario/FrancisBattleTwoPianos.mid\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Nintendo/Wii/SuperMarioGalaxy/EndTitleTwoPianos.mid\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Nintendo/SNES/LufiaTheFortressofDoom/EndingFourHands.mid\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Nintendo/SNES/Terranigma/EvergreenForest.mid\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Nintendo/NDS/Pok�monDiamondVersionPok�monPearlVersion/Route205DayTwoPianos.mid\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Other/MUL/TheLegendofZeldaBreathoftheWild/SpiritOrbObtainedFourHands.mid\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Other/MUL/SonicUnleashed/WindmillIsleDayTwoPianos.mid\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Sony/PS5/RatchetClankRiftApart/OdetoNefarious.mid\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Nintendo/GBA/MarioKartSuperCircuit/Credits.mid\n",
        "\n",
        "# remove hidden files\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Nintendo/3DS/FireEmblemAwakening/.mid\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Other/PC/BugFablesTheEverlastingSapling/.mid\n",
        "\n",
        "# large file\n",
        "!rm /root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Other/PC/Lenen2EarthenMiraculousSword/MonoEyeIronicFATE.mid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3mSGyKCmGppb"
      },
      "outputs": [],
      "source": [
        "def get_file_paths(path: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Returns a list of all absolute file paths for each song.\n",
        "    \"\"\"\n",
        "    file_paths = []\n",
        "    for entry in os.listdir(path):\n",
        "        full_path = os.path.join(path, entry)\n",
        "        if os.path.isdir(full_path):\n",
        "            file_paths.extend(get_file_paths(full_path))\n",
        "        else:\n",
        "            file_paths.append(full_path)\n",
        "    return file_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jtqZWxqrGsFK"
      },
      "outputs": [],
      "source": [
        "def sort_files_by_name(file_paths: list[str]) -> list[str]:\n",
        "    \"\"\"\n",
        "    assume song names are unique.\n",
        "    for consistent train/val/test split after setting random seed.\n",
        "    \"\"\"\n",
        "    names = dict()\n",
        "    for full_path in file_paths:\n",
        "        name = ''.join(full_path.split('/')[12:15][::-1])\n",
        "        names[name] = full_path\n",
        "    keys = list(names.keys())\n",
        "    keys.sort()\n",
        "    return [names[key] for key in keys]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rghg1wo3GufT"
      },
      "outputs": [],
      "source": [
        "# get a list of all absolute paths to the midi files in the dataset\n",
        "file_paths = get_file_paths(path + '/nin_midi_files/nin_midi_files')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dmZ5j7BGxGS"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "N8GjUFn-PpvJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Seq2Seq(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, batch_size, sequence_length):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_size = batch_size\n",
        "        self.sequence_length = sequence_length\n",
        "        super(Seq2Seq, self).__init__()\n",
        "\n",
        "        self.encoder = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout = 0.4)  # dropout should be validated\n",
        "        # self.encoder = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)  # dropout should be validated\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        # consider birdirectional= False, bias = True, proj_size, num_layer =1\n",
        "        # or consider dropout(encoder), its only between different stacked layers\n",
        "        self.decoder = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, input_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, X, Y):\n",
        "        _, (h, c) = self.encoder(X)\n",
        "        output, _ = self.decoder(Y, (h, c))\n",
        "        output = self.fc(output)\n",
        "        # output = self.softmax(output)\n",
        "        # output = self.sigmoid(output)  # TODO\n",
        "\n",
        "        #output = self.sigmoid(output)\n",
        "        #output = torch.from_numpy(np.where(output > 0.5, 1, 0)).type(torch.float32)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aQDEAWoRcVRO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QxguW7gHGycb"
      },
      "outputs": [],
      "source": [
        "random.seed(10)\n",
        "sorted_file_paths = sort_files_by_name(file_paths)\n",
        "random.shuffle(sorted_file_paths)\n",
        "\n",
        "train_files = sorted_file_paths[:3500]\n",
        "valid_files = sorted_file_paths[3500:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5peo4g1fgkl",
        "outputId": "767820d6-8d91-4bcb-f762-6cd62b54a047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 128)\n",
            "torch.Size([4450, 149, 128])\n"
          ]
        }
      ],
      "source": [
        "# piano_roll, tempo, resolution = parseMidi(touhou_bad_apple)\n",
        "#X, Y = createTrainData([piano_roll], 500, 50)\n",
        "X, Y = createTrainData(getData(train_files[0:70]), 149, 1)  # slow\n",
        "# train_data_set = createTrainData(getData(train_files[0:20]), 100, 10)\n",
        "#valid_data = createTrainData(getData(valid_files), 100, 10)\n",
        "# train_data =  torch.from_numpy(train_data_set[0]).type(torch.float32)\n",
        "# train_labels = torch.from_numpy(train_data_set[1]).type(torch.float32)\n",
        "# print(train_data.shape)\n",
        "# print(X)\n",
        "# print(Y)\n",
        "#file_paths1 = get_file_paths(path + '/nin_midi_files/nin_midi_files')\n",
        "#FluidSynth(\"font.sf2\").midi_to_audio(file_paths[0], 'abc.wav')\n",
        "#display.Audio(\"abc.wav\")\n",
        "x = torch.from_numpy(X).type(torch.float32)\n",
        "y = torch.from_numpy(Y).type(torch.float32)\n",
        "lst = []\n",
        "for batch_size in range(x.shape[0]):\n",
        "  temp = np.vstack((np.array(x[batch_size]), np.array(y[batch_size])))\n",
        "  #print(temp.shape)\n",
        "  lst.append(temp)\n",
        "\n",
        "print(lst[0].shape)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vsZv2fxwU_eb"
      },
      "outputs": [],
      "source": [
        "# rnn = nn.LSTM(10, 20, 2)\n",
        "# input = torch.randn(5, 3, 10)\n",
        "# h0 = torch.randn(2, 3, 20)\n",
        "# c0 = torch.randn(2, 3, 20)\n",
        "# output, (hn, cn) = rnn(input, (h0, c0))\n",
        "# print(output.shape)\n",
        "\n",
        "# test the actual class\n",
        "# print(\"X,Y: \", x.shape,y.shape)\n",
        "# x -> batch size , sequence length , note vocab\n",
        "# y-> batch size , target sequence length , note vocab\n",
        "#model = Seq2Seq()\n",
        "# encoder = nn.LSTM(128, 128, 1, batch_first=True)\n",
        "# context, (h ,c) = encoder(x)\n",
        "# print(\"context:\",context[0].shape)\n",
        "# decoder = nn.LSTM(128, 128, 1, batch_first=True)\n",
        "# context, (h, c) = decoder(y, (h,c))\n",
        "# print(h.shape)\n",
        "# print(output.shape)\n",
        "# fc = nn.Linear(128,128)\n",
        "# output = fc(output)\n",
        "# print(output.shape)\n",
        "# sig = nn.Sigmoid()\n",
        "# output = sig(output)\n",
        "# print(output.shape)\n",
        "# print(output[0][0].shape)\n",
        "# print(output[0][0])\n",
        "# output = np.where(output > 0.5,1, 0)\n",
        "# print(output[0][0])\n",
        "# print(len(output[0][0]))\n",
        "#print(output[0])\n",
        "#output = model(input)\n",
        "#print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdZsqVm2PrbM",
        "outputId": "ce5de9cd-c6af-4287-9a1b-ce4ac8bcce70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 150, 128])\n",
            "torch.Size([100, 50, 128])\n",
            "torch.Size([100, 100, 128])\n",
            "torch.Size([100, 150, 128])\n",
            "torch.Size([100, 50, 128])\n",
            "torch.Size([100, 100, 128])\n",
            "torch.Size([100, 150, 128])\n",
            "torch.Size([100, 50, 128])\n",
            "torch.Size([100, 100, 128])\n",
            "torch.Size([100, 150, 128])\n",
            "torch.Size([100, 50, 128])\n",
            "torch.Size([100, 100, 128])\n",
            "torch.Size([100, 150, 128])\n",
            "torch.Size([100, 50, 128])\n",
            "torch.Size([100, 100, 128])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "train_data_loader = DataLoader(lst, batch_size=100, shuffle=True)\n",
        "num = 0\n",
        "for data in train_data_loader:\n",
        "    print(data.shape)\n",
        "    print(data[:,100:,:].shape)\n",
        "    print(data[:,:100,:].shape)\n",
        "    if num ==4:\n",
        "      break;\n",
        "    num+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ue7RyS1xPu8z"
      },
      "outputs": [],
      "source": [
        "def collate_data(batch, input_seq_len):\n",
        "  X, labels = [], []\n",
        "  for data in batch:\n",
        "    #print(data.shape)\n",
        "    labels.append(data[input_seq_len:,:])\n",
        "    X.append(data[:input_seq_len,:])\n",
        "\n",
        "  X = torch.from_numpy(np.array(X)).type(torch.float32)\n",
        "  labels = torch.from_numpy(np.array(labels)).type(torch.float32)\n",
        "  #print(X.shape ,labels.shape, \"COLLATE\")\n",
        "\n",
        "  return X, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XYD0LYexP9_8"
      },
      "outputs": [],
      "source": [
        "#!pip install torchmetrics\n",
        "import torch\n",
        "try:\n",
        "    import torchmetrics\n",
        "except ModuleNotFoundError:\n",
        "    !pip install torchmetrics\n",
        "    import torchmetrics\n",
        "from torchmetrics.classification import MultilabelF1Score\n",
        "\n",
        "def accuracy(model, dataset, input_seq_len, max=1000):\n",
        "    \"\"\"\n",
        "    Estimate the accuracy of `model` over the `dataset`.\n",
        "    We will take the **most probable class**\n",
        "    as the class predicted by the model.\n",
        "\n",
        "    Parameters:\n",
        "        `model`   - An object of class nn.Module\n",
        "        `dataset` - A dataset of the same type as `train_data`.\n",
        "        `max`     - The max number of samples to use to estimate\n",
        "                    model accuracy\n",
        "\n",
        "    Returns: a floating-point value between 0 and 1.\n",
        "    \"\"\"\n",
        "\n",
        "    correct, total = 0, 0\n",
        "    dataloader = DataLoader(dataset,\n",
        "                            batch_size=1,  # use batch size 1 to prevent padding\n",
        "                            collate_fn= lambda batch :collate_data(batch, input_seq_len=100) )\n",
        "    pred = []\n",
        "    targets = []\n",
        "    for i, (x, t) in enumerate(dataloader):\n",
        "        z = model(x,t)\n",
        "        cond = z > 0.5\n",
        "        z2 =torch.sigmoid(z)\n",
        "        z2 = torch.where(cond, 1, 0)\n",
        "        #print(z2.shape, t.shape, \"shapes\")\n",
        "        pred.append(z2)\n",
        "        targets.append(t)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    a = torch.cat(pred, dim =0)\n",
        "    b = torch.cat(targets, dim =0)\n",
        "    print(a.shape, b.shape)\n",
        "    metric = torchmetrics.classification.Accuracy(task = \"multiclass\", num_classes=128)\n",
        "    acc = metric(a, b)\n",
        "    return acc.item()\n",
        "\n",
        "def accuracy2(model, dataset, input_seq_len, max=1000):\n",
        "    \"\"\"\n",
        "    Estimate the accuracy of `model` over the `dataset`.\n",
        "    We will take the **most probable class**\n",
        "    as the class predicted by the model.\n",
        "\n",
        "    Parameters:\n",
        "        `model`   - An object of class nn.Module\n",
        "        `dataset` - A dataset of the same type as `train_data`.\n",
        "        `max`     - The max number of samples to use to estimate\n",
        "                    model accuracy\n",
        "\n",
        "    Returns: a floating-point value between 0 and 1.\n",
        "    \"\"\"\n",
        "\n",
        "    correct, total = 0, 0\n",
        "    dataloader = DataLoader(dataset,\n",
        "                            batch_size=1,  # use batch size 1 to prevent padding\n",
        "                            collate_fn= lambda batch :collate_data(batch, input_seq_len=100) )\n",
        "    pred = []\n",
        "    targets = []\n",
        "    count  =0\n",
        "    for i, (x, t) in enumerate(dataloader):\n",
        "        z = model(x,t)\n",
        "        #z = torch.sigmoid(z)\n",
        "        #n = torch.nn.Sigmoid()\n",
        "        #z = n(z)\n",
        "        z = (z > 0.1).int()\n",
        "        pred.append(z.squeeze(0))\n",
        "        targets.append(t.squeeze(0))\n",
        "        count = i\n",
        "        #print(z.shape, t.shape, x.shape, \"SHAPES\") #  both are 1, 10, 128\n",
        "\n",
        "\n",
        "    print(z)\n",
        "    a = torch.cat(pred, dim =0)\n",
        "    b = torch.cat(targets, dim =0)\n",
        "    print(a.shape, b.shape)\n",
        "    metric = torchmetrics.classification.MultilabelAccuracy(num_labels=128)\n",
        "    acc = metric(a, b)\n",
        "    return acc.item()\n",
        "    #return np.count(a != b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "fEhozob1Q3i0"
      },
      "outputs": [],
      "source": [
        "# device = 'cuda' if torch.cuda.is_available()  else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYTRzEkQd6De",
        "outputId": "9041f3a6-74f2-4058-a96a-8f81c6f52ee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torch\n",
        "minecraft_sweden = '/root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Other/PC/Minecraft/Sweden.mid'\n",
        "touhou_bad_apple = '/root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Other/PC/Touhou4LotusLandStory/BadApple.mid'\n",
        "ffxiv_uldah = '/root/.cache/kagglehub/datasets/hansespinosa2/nin-video-game-midis/versions/2/nin_midi_files/nin_midi_files/Other/PC/FinalFantasyXIV/TheTwinFacesofFateTheThemeofUldah.mid'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "Zsg0U8tR_Jxi",
        "outputId": "88f7cb5d-fb48-444a-a1fd-1999202d2c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 150, 128]) torch.Size([100, 0, 128])\n",
            "140.79100762226238\n",
            "Epoch:  0\n",
            "torch.Size([100, 1, 128])\n",
            "model shape torch.Size([100, 1, 128])\n",
            "torch.Size([100, 149, 128]) data\n",
            "torch.Size([100, 1, 128])\n",
            "tensor(0.1052, grad_fn=<MaxBackward1>)\n",
            "torch.Size([100, 1, 128])\n",
            "model shape torch.Size([100, 1, 128])\n",
            "torch.Size([100, 149, 128]) data\n",
            "torch.Size([100, 1, 128])\n",
            "tensor(0.1108, grad_fn=<MaxBackward1>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-e722227a6732>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimbalance_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m149\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# last param is input len for 150 len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;31m#data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-e722227a6732>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, val_data, learning_rate, batch_size, num_epochs, model, input_seq_len)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miter_count\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mplot_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0miters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0;31m#va = accuracy(model, val_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-0380ab876495>\u001b[0m in \u001b[0;36maccuracy2\u001b[0;34m(model, dataset, input_seq_len, max)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mcount\u001b[0m  \u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;31m#z = torch.sigmoid(z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m#n = torch.nn.Sigmoid()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-b3f59c369d40>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m# output = self.softmax(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# output = self.sigmoid(output)  # TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_data_loader = DataLoader(lst, batch_size=100, shuffle=True)\n",
        "for data in train_data_loader:\n",
        "  X,label = collate_data(data, 500)\n",
        "  print(X.shape, label.shape)\n",
        "  break;\n",
        "\n",
        "# might have to add in sequence ength for data,target as paramter\n",
        "def train(train_data, val_data, learning_rate, batch_size, num_epochs, model, input_seq_len):\n",
        "\n",
        "    dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True,\n",
        "                            collate_fn= lambda batch :collate_data(batch, input_seq_len))\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    #loss_fn = nn.CrossEntropyLoss()  # change back to BCE later maybe\n",
        "\n",
        "    #imbalance_ratio = 100\n",
        "    positive_weight = torch.tensor([imbalance_ratio])\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=positive_weight)\n",
        "\n",
        "    iters, train_loss, train_acc, val_acc = [], [], [], []\n",
        "    iter_count = 0 # count the number of iterations that has passed\n",
        "    plot_every = 2\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch: \", epoch)\n",
        "        for ind, (data, labels) in enumerate(dataloader):\n",
        "            z = model(data, labels)\n",
        "            print(z.shape)\n",
        "            print(\"model shape\", z.shape)\n",
        "            #z = np.where(z > 0.5,1, 0)\n",
        "            #??z = torch.tensor(z, dtype=torch.float32,requires_grad=True)\n",
        "            loss = loss_fn(z, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            #   torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "            optimizer.step()\n",
        "            print(data.shape, \"data\")\n",
        "            print(labels.shape)\n",
        "            print(torch.max(z[0]))\n",
        "            #break;\n",
        "\n",
        "            iter_count += 1\n",
        "            if iter_count % plot_every == 0:\n",
        "                iters.append(iter_count)\n",
        "                ta = accuracy2(model, train_data, input_seq_len)\n",
        "                #va = accuracy(model, val_data)\n",
        "                train_loss.append(float(loss))\n",
        "                train_acc.append(ta)\n",
        "                #val_acc.append(va)\n",
        "                print(iter_count, \"Loss:\", float(loss), \"Train Acc:\", ta, \"Val Acc:\", None)\n",
        "model = Seq2Seq(128, 128, 2, 10, 10)\n",
        "# model.to(device)\n",
        "train_loader = DataLoader(lst,batch_size = 1, collate_fn= lambda batch :collate_data(batch, 100))\n",
        "total_notes = 0\n",
        "num_notes_played = 0\n",
        "for (x,t) in train_loader:\n",
        "  total_notes += t.numel()\n",
        "  num_notes_played += t.sum().item()\n",
        "imbalance_ratio = (total_notes - num_notes_played) / num_notes_played\n",
        "print(imbalance_ratio)\n",
        "\n",
        "train(lst, None, 0.001, 100, num_epochs=100, model=model, input_seq_len=149)  # last param is input len for 150 len\n",
        "#data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoHggG2I7jEB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssBNJsJHiZKe"
      },
      "outputs": [],
      "source": [
        "# Example tensors\n",
        "y_true = torch.tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]).type(torch.float32)\n",
        "y_pred = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]).type(torch.float32)\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "print(loss(y_pred, y_true))\n",
        "\n",
        "y_true = torch.tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]).type(torch.float32)\n",
        "y_pred = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]).type(torch.float32)\n",
        "\n",
        "loss_bce = nn.BCEWithLogitsLoss()\n",
        "print(loss_bce(y_pred, y_true))\n",
        "\n",
        "y1 = torch.tensor([0.1,0.2,0.4,0.6])\n",
        "y2 = torch.tensor([1,0,1,0])\n",
        "#!pip install torcheval\n",
        "#import torch, torcheval, torchmetrics\n",
        "#from torcheval.metrics.functional import multiclass_f1_score\n",
        "\n",
        "# Initialize the metric\n",
        "metric = torchmetrics.classification.Accuracy(task = \"multiclass\", num_classes=4)\n",
        "acc = metric(y1, y2)\n",
        "print(acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H_HhZd5jRUxg"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, song, pred_len):\n",
        "    # song should be formatted as tensor\n",
        "    # seq = song.shape[0]-10\n",
        "    # a = model(song[:seq], song[seq:])\n",
        "    preds = 0\n",
        "    while preds < 2:\n",
        "        seq = song.shape[0] - pred_len\n",
        "        preds += 1\n",
        "        print(song[:seq].shape)\n",
        "        z = model(song[(seq -2400):seq], song[seq:])\n",
        "        # z = torch.sigmoid(z)\n",
        "        # cond = z > 0.5\n",
        "        z = torch.sigmoid(z)\n",
        "        z = (z > 0.54).int()\n",
        "        # z2 = torch.where(cond, 1, 0)\n",
        "        # print(z.shape)\n",
        "        # print(z)\n",
        "        # print(z == 1)\n",
        "        song = torch.cat([song, z])\n",
        "    return song\n",
        "\n",
        "\n",
        "# not 1\n",
        "print(valid_files[4])\n",
        "#song = getData([valid_files[1]])\n",
        "song, tempo, resolution = parseMidi(valid_files[4])\n",
        "print(song.shape)\n",
        "song = torch.tensor(song).type(torch.float32)\n",
        "#song = torch.from_numpy(song)\n",
        "#song = torch.from_numpy(song).type(torch.float32)\n",
        "print(song.shape)\n",
        "ext = evaluate(model, song.squeeze(0), 2000)\n",
        "print(ext.shape)\n",
        "#print(song.shape)\n",
        "new_midi = outputMidi(\"new_midi.midi\", ext.detach().numpy(), tempo = tempo, resolution = resolution)\n",
        "display_piano_roll(ext.detach().numpy(), \"new_midi\")\n",
        "play_midi(\"new_midi.midi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtUKeUzgXwvT"
      },
      "outputs": [],
      "source": [
        "def evaluate2(model, song, pred_len):\n",
        "    # song should be formatted as tensor\n",
        "    # seq = song.shape[0]-10\n",
        "    # a = model(song[:seq], song[seq:])\n",
        "    preds = 0\n",
        "    # src = song[-200:-10,:]\n",
        "    src = song[-1400:,:]\n",
        "    tgt = song[-10:,:]\n",
        "    while preds < 2500:\n",
        "        seq = song.shape[0] - pred_len\n",
        "        # print(song[:seq].shape)\n",
        "        z = model(src, tgt)\n",
        "        z = torch.softmax(z, 1)\n",
        "        # cond = z > 0.5\n",
        "        z = (z > 0.0085).int()\n",
        "        # z = (z > 0.5).int()\n",
        "        # z2 = torch.where(cond, 1, 0)\n",
        "        # print(z.shape)\n",
        "        # print(z)\n",
        "        # print(z == 1)\n",
        "        # src = torch.cat((src[-199:,:], tgt)).type(torch.float32)\n",
        "        tgt = z.type(torch.float32)\n",
        "        song = torch.cat([song, z]).type(torch.float32)\n",
        "        preds += z.shape[0]\n",
        "    return song\n",
        "\n",
        "\n",
        "# not 1\n",
        "print(valid_files[0])\n",
        "#song = getData([valid_files[1]])\n",
        "song, tempo, resolution = parseMidi(valid_files[0])\n",
        "print(song.shape)\n",
        "song = torch.tensor(song).type(torch.float32)\n",
        "#song = torch.from_numpy(song)\n",
        "#song = torch.from_numpy(song).type(torch.float32)\n",
        "print(song.shape)\n",
        "ext = evaluate2(model, song.squeeze(0), 10)\n",
        "print(ext.shape)\n",
        "new_midi = outputMidi(\"new_midi.midi\", ext.detach().numpy(), tempo = tempo, resolution = resolution)\n",
        "display_piano_roll(ext.detach().numpy(), \"new_midi\")\n",
        "play_midi(\"new_midi.midi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbYg-Du0pFbw"
      },
      "outputs": [],
      "source": [
        "#piano_roll, tempo, resolution = parseMidi(valid_files[0])\n",
        "new_midi = outputMidi(\"new_midi.midi\", ext.detach().numpy(), tempo = tempo, resolution = resolution)\n",
        "print(ext.shape)\n",
        "display_piano_roll(song.detach().numpy(), \"new_midi\")\n",
        "# play_midi(\"new_midi.midi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayhTpMlcqgmc"
      },
      "outputs": [],
      "source": [
        "play_midi(valid_files[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QE74CAw2YJf"
      },
      "outputs": [],
      "source": [
        "display_piano_roll(ext.detach().numpy(), \"original\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JDo-GMsdFcBb",
        "j2Q99xKnFyIj",
        "_W5qGyaWGj2o"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}